0x03. Log Parsing
Algorithm
Python


Log parsing is the process of extracting relevant information and structured data from log files. Log files contain records of events or activities generated by various systems, applications, or devices. They are commonly used for troubleshooting, monitoring, and analysis purposes.


A log parsing algorithm is a set of instructions or a code implementation that automates the process of parsing log files. It typically involves pattern matching, regular expressions, and text processing techniques to extract meaningful data from the log entries.


Keep in mind that the log parsing algorithm needs to be tailored to the specific log file format you're working with. The regular expression pattern used in the example above might not match the format of your log file exactly, so you may need to modify it accordingly.



Requirements
General
Allowed editors: vi, vim, emacs
All your files will be interpreted/compiled on Ubuntu 14.04 LTS using python3 (version 3.4.3)
All your files should end with a new line
The first line of all your files should be exactly #!/usr/bin/python3
A README.md file, at the root of the folder of the project, is mandatory
Your code should use the PEP 8 style (version 1.7.x)
All your files must be executable
The length of your files will be tested using wc



Example in this file 0-generator.py
#!/usr/bin/python3
import random
import sys
from time import sleep
import datetime

for i in range(10000):
    sleep(random.random())
    sys.stdout.write("{:d}.{:d}.{:d}.{:d} - [{}] \"GET /projects/260 HTTP/1.1\" {} {}\n".format(
        random.randint(1, 255), random.randint(1, 255), random.randint(1, 255), random.randint(1, 255),
        datetime.datetime.now(),
        random.choice([200, 301, 400, 401, 403, 404, 405, 500]),
        random.randint(1, 1024)
    ))
    sys.stdout.flush()


The above code generates simulated log entries in the Common Log Format (CLF). It continuously writes 10,000 log entries to the standard output (stdout).


#!/usr/bin/python3
This line is called a shebang and is used to specify the interpreter to be used when executing the script. In this case, it indicates that the script should be run using Python 3.


import random
import sys
from time import sleep
import datetime
These lines import the necessary modules for the code: random for generating random numbers, sys for writing to stdout, sleep for introducing delays, and datetime for obtaining the current timestamp.


for i in range(10000):
This for loop iterates 10,000 times, generating log entries in each iteration.


    sleep(random.random())
This line introduces a random delay using the sleep function from the time module. The random.random() function generates a random floating-point number between 0 and 1, causing the script to pause for a random amount of time before generating the next log entry.



    sys.stdout.write("{:d}.{:d}.{:d}.{:d} - [{}] \"GET /projects/260 HTTP/1.1\" {} {}\n".format(
        random.randint(1, 255), random.randint(1, 255), random.randint(1, 255), random.randint(1, 255),
        datetime.datetime.now(),
        random.choice([200, 301, 400, 401, 403, 404, 405, 500]),
        random.randint(1, 1024)
    ))

This line generates a log entry in the Common Log Format (CLF) and writes it to the stdout using sys.stdout.write(). The log entry consists of an IP address, timestamp, HTTP request, response code, and response size. The IP address is generated by concatenating four random numbers between 1 and 255 separated by periods. The timestamp is obtained using datetime.datetime.now(). The HTTP request is fixed as "GET /projects/260 HTTP/1.1". The response code is randomly chosen from a list of HTTP status codes. The response size is a random integer between 1 and 1024.



    sys.stdout.flush()
This line flushes the stdout buffer, ensuring that the log entry is immediately written rather than waiting for the buffer to fill up.

Overall, this code simulates log entries in the Common Log Format and continuously writes them to stdout, mimicking the behavior of a web server generating access logs.






Example in this file 0-stats.py
#!/usr/bin/python3
"""
reads stdin line by line and computes metrics
"""
import sys

if __name__ == "__main__":

    file_size = 0
    count = 0
    sum_codes = {
        '200': 0,
        '301': 0,
        '400': 0,
        '401': 0,
        '403': 0,
        '404': 0,
        '405': 0,
        '500': 0,
    }

    def print_codes(sum_codes, size):
        """
        print info
        """
        print('File size: {}'.format(size))
        for code, count in sorted(sum_codes.items()):
            if count > 0:
                print('{}: {}'.format(code, count))

    try:
        for line in sys.stdin:
            count += 1
            input_array = line.split()
            try:
                file_size += int(input_array[-1])
                code = input_array[-2]
                if code in sum_codes:
                    sum_codes[code] += 1
            except Exception:
                pass
            if count % 10 == 0:
                print_codes(sum_codes, file_size)
    except KeyboardInterrupt:
        print_codes(sum_codes, file_size)
        raise
    print_codes(sum_codes, file_size)


    The code reads input from the standard input (stdin) line by line and computes metrics based on the input. It focuses on processing log data related to file sizes and HTTP status codes.


    #!/usr/bin/python3
This line is a shebang that specifies the interpreter to be used when executing the script. In this case, it indicates that the script should be run using Python 3.



file_size = 0
count = 0
sum_codes = {
    '200': 0,
    '301': 0,
    '400': 0,
    '401': 0,
    '403': 0,
    '404': 0,
    '405': 0,
    '500': 0,
}

These lines initialize variables for file size, count, and a dictionary sum_codes to store the counts of different HTTP status codes encountered.



def print_codes(sum_codes, size):
    """
    print info
    """
    print('File size: {}'.format(size))
    for code, count in sorted(sum_codes.items()):
        if count > 0:
            print('{}: {}'.format(code, count))

This function print_codes prints the file size and the counts of different HTTP status codes. It iterates over the sum_codes dictionary, sorting the items, and printing only the codes with a count greater than zero.



try:
    for line in sys.stdin:
        count += 1
        input_array = line.split()
        try:
            file_size += int(input_array[-1])
            code = input_array[-2]
            if code in sum_codes:
                sum_codes[code] += 1
        except Exception:
            pass
        if count % 10 == 0:
            print_codes(sum_codes, file_size)
except KeyboardInterrupt:
    print_codes(sum_codes, file_size)
    raise
print_codes(sum_codes, file_size)


The main part of the code reads lines from stdin in a loop. For each line, it increments the count variable by 1. It splits the line into an array input_array using whitespace as the delimiter.

Within a try-except block, it tries to extract the file size from input_array[-1] (last element) and converts it to an integer, adding it to the file_size variable. It also extracts the HTTP status code from input_array[-2] and checks if it is present in the sum_codes dictionary. If so, it increments the count for that status code.

If an exception occurs during the extraction and conversion process, it is caught and ignored with the pass statement.

After processing every 10 lines (determined by count % 10 == 0), it calls the print_codes function to print the current file size and status code counts.

The script handles the KeyboardInterrupt exception, which occurs when the user interrupts the execution (e.g., by pressing Ctrl+C). In this case, it prints the current file size and status code counts and then raises the exception again to terminate the script.

Finally, after processing all the lines, it calls print_codes one last time to print the final file size and status code counts.

Overall, this code reads log data from stdin, tracks the file size and counts of different HTTP status codes encountered, and prints the metrics at regular intervals and upon script termination.

